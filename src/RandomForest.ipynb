{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training DT\n",
      "confusion_matrix [[3933   43]\n",
      " [  90   60]]\n",
      "accuracy_score 0.9677653902084343\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "POS_DICT = []\n",
    "BIO_DICT = []\n",
    "PATH_DICT = []\n",
    "\n",
    "def index_list(dict, key):\n",
    "    if key in dict:\n",
    "        return dict.index(key)\n",
    "    else:\n",
    "        dict.append(key)\n",
    "        return dict.index(key)\n",
    "\n",
    "def read_data(pth):\n",
    "    pairs_data = []\n",
    "    sentence = []\n",
    "    with open(pth, 'r') as file:\n",
    "        lines_in = file.read().split('\\n')\n",
    "        for line in lines_in:\n",
    "            if line == '':\n",
    "                if sentence == '' or len(sentence) < 3:\n",
    "                    sentence = []\n",
    "                    continue\n",
    "                # print(\"s\", sentence)\n",
    "                pairs_data += find_pair(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            else:\n",
    "                sentence.append(line)\n",
    "    # print(\"pairs_data\", pairs_data)\n",
    "    return pairs_data\n",
    "\n",
    "def find_pair(sentence):\n",
    "    pairs_data = []\n",
    "    whole_POS_path = []\n",
    "    whole_BIO_path = [] # ------TODO: introduce BIO path-------\n",
    "    for i, word in enumerate(sentence):\n",
    "        data = word.split('\\t')\n",
    "        whole_POS_path.append(data[1])\n",
    "        whole_BIO_path.append(data[2])\n",
    "        if len(data) < 6:\n",
    "            continue\n",
    "        if data[5] == \"ARG1\":\n",
    "            ARG_POS = data[1]\n",
    "            ARG_BIO = data[2]\n",
    "            ARG_num = data[3]\n",
    "\n",
    "        elif data[5] == \"PRED\":\n",
    "            PRED_POS = data[1]\n",
    "            PRED_BIO = data[2]\n",
    "            PRED_num = data[3]\n",
    "            PRED_index = i\n",
    "\n",
    "    for i, word in enumerate(sentence):\n",
    "        data = word.split('\\t')\n",
    "        if i == PRED_index:\n",
    "            continue\n",
    "        if i < PRED_index:\n",
    "            current_path = [whole_POS_path[x] for x in range(i, PRED_index+1)]\n",
    "        else:\n",
    "            current_path = [whole_POS_path[x] for x in range(PRED_index, i+1)]\n",
    "        current_path = ','.join(current_path)\n",
    "        if len(data) == 6 and data[5] == \"ARG1\":\n",
    "            role = 1\n",
    "        else:\n",
    "            role = 0\n",
    "        pairs_data.append([index_list(POS_DICT, PRED_POS)] + [index_list(BIO_DICT, PRED_BIO)]\n",
    "                          + [index_list(POS_DICT, data[1])] + [index_list(BIO_DICT, data[2])]\n",
    "                          + [int(PRED_num) - int(data[3])] + [index_list(PATH_DICT, current_path)]\n",
    "                          + [role])\n",
    "    return pairs_data\n",
    "\n",
    "def onehot_pair(pairs, withpth=1):\n",
    "    res = []\n",
    "    for pair in pairs:\n",
    "        t1 = [0 for x in range(len(POS_DICT))]\n",
    "        t1[pair[0]] = 1\n",
    "        t2 = [0 for x in range(len(BIO_DICT))]\n",
    "        t2[pair[1]] = 1\n",
    "        t3 = [0 for x in range(len(POS_DICT))]\n",
    "        t3[pair[2]] = 1\n",
    "        t4 = [0 for x in range(len(BIO_DICT))]\n",
    "        t4[pair[3]] = 1\n",
    "        if withpth:\n",
    "            t5 = [0 for x in range(len(PATH_DICT))]\n",
    "            t5[pair[4]] = 1\n",
    "            res.append(t1 + t2 + t3 + t4 + t5 + [pair[6]] )\n",
    "        else:\n",
    "            res.append(t1 + t2 + t3 + t4 + [pair[6]])\n",
    "    return np.array(res)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    pair_train = np.load(\"train.npy\")# loaded by function \"read_data\"\n",
    "    x = pair_train[:, 0:-1]\n",
    "    y = pair_train[:, -1]\n",
    "\n",
    "    # pair_test = onehot_pair(np.load(\"dev.npy\"), withpth=0)\n",
    "    pair_test = np.load(\"test.npy\")\n",
    "    x_test = pair_test[:, 0:-1]\n",
    "    y_test = pair_test[:, -1]\n",
    "\n",
    "    print(\"training DT\")\n",
    "    clf = RandomForestClassifier(n_estimators=100, criterion="gini", min_samples_split=10, max_features="auto", n_jobs=4)  \n",
    "    clf.fit(x, y)  \n",
    "    y_pred_DT = clf.predict(x_test) \n",
    "    print(\"confusion_matrix\", confusion_matrix(y_test, y_pred_DT))\n",
    "    print(\"accuracy_score\", accuracy_score(y_test,y_pred_DT))\n",
    "\n",
    "    N = 0\n",
    "\n",
    "\n",
    "    with open(\"%-test\", 'r') as file_in:\n",
    "        with open(\"partitive.txt\", 'w') as file_out:\n",
    "            lines_in = file_in.read().split('\\n')\n",
    "            for line in lines_in:\n",
    "                data = line.split(\"\\t\")\n",
    "                if line == '':\n",
    "                    file_out.write(\"\\n\")\n",
    "                    continue\n",
    "                if len(data) == 6 and data[5] == \"PRED\":\n",
    "                    file_out.write(line + \"\\n\")\n",
    "                    continue\n",
    "                if len(data) < 6:\n",
    "                    data.append(\"\")\n",
    "                if y_pred_DT[N] == 1:\n",
    "                    data[5] = \"ARG1\"\n",
    "                else:\n",
    "                    data[5] = \"\"\n",
    "                N += 1\n",
    "                file_out.write(\"\\t\".join(data) + \"\\n\")\n",
    "    assert N == len(y_pred_DT)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
